{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a82f70-b99f-4163-864a-72d52ac8379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb5e61f-49c2-435e-b851-39aeefd9c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Aditya kumar Dubey\\OneDrive\\Apps\\Documents\\Desktop\\Data\\Titanic-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929e11a8-c07e-4fb8-b3de-115381421010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a29c7f-2864-4483-96e9-e31f74105d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use single brackets around \"Name\" because CountVectorizer expects 1-D input\n",
    "X = df['Name']\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7f52a7-35b5-4835-8880-368817b239ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed76915-2cfa-4eb1-b24f-f5c05fd42c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8001820350260498"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the pipeline using default parameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d028e5ae-05ad-455c-83df-f3fbd5c37ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameter values to search (use a distribution for any continuous parameters)\n",
    "import scipy as sp\n",
    "params = {}\n",
    "params['countvectorizer__min_df'] = [1, 2, 3, 4]\n",
    "params['countvectorizer__lowercase'] = [True, False]\n",
    "params['multinomialnb__alpha'] = sp.stats.uniform(scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611c46f9-ec31-473b-84ea-6f119d1cea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try \"n_iter\" random combinations of those parameter values\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rand = RandomizedSearchCV(pipe, params, n_iter=10, cv=5, scoring='accuracy', random_state=1)\n",
    "rand.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51024c8e-056a-4d12-8859-4e7a3b5a75ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8080534806352395"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was the best score found during the search?\n",
    "rand.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09ac404-e4cc-450d-8029-aae95221d01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__lowercase': False,\n",
       " 'countvectorizer__min_df': 3,\n",
       " 'multinomialnb__alpha': 0.1981014890848788}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which combination of parameters produced the best score?\n",
    "rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427728b-573b-4e70-ab09-5ea776d78192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e683e6ad-3abf-4237-b23d-558f3c3d4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 1 1 0 1 0]\n",
      " [0 1 1 1 0 2 0 1 1]]\n",
      "['amazing' 'and' 'are' 'deep' 'is' 'learning' 'love' 'machine' 'popular']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text corpus\n",
    "documents = [\n",
    "    \"I love machine learning\",\n",
    "    \"Machine learning is amazing\",\n",
    "    \"Deep learning and machine learning are popular\"\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array\n",
    "print(X.toarray())\n",
    "\n",
    "# Get the feature names (vocabulary)\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc764135-dc76-424c-80c2-e5466cb1d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 13 stored elements and shape (3, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 5)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455cb44-c667-4852-ba04-41366a6907a2",
   "metadata": {},
   "source": [
    "Counter-vectorization refers to the process of converting text data into numerical vectors, where each word or token in the text is represented by its frequency (or count) in the document. It is most commonly achieved using a **CountVectorizer** (like in Scikit-learn), which creates a document-term matrix where each entry corresponds to the frequency of a word in a given document.\n",
    "\n",
    "The idea is to represent text as a collection of **word counts** rather than raw text, making it suitable for machine learning algorithms that work with numerical data.\n",
    "\n",
    "### **Key Points of Counter-Vectorization**\n",
    "1. **Tokenization**: The process of breaking the text into individual words (tokens).\n",
    "2. **Vocabulary Creation**: Building a list of unique words (the vocabulary) that appear in the dataset.\n",
    "3. **Frequency Count**: For each document, counting how often each word in the vocabulary appears.\n",
    "4. **Document-Term Matrix**: A matrix where rows represent documents and columns represent words, with each value being the frequency of that word in the respective document.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of Counter-Vectorization**\n",
    "Imagine you have the following three sentences:\n",
    "1. \"I love data science.\"\n",
    "2. \"Data science is amazing.\"\n",
    "3. \"Machine learning and data science are important.\"\n",
    "\n",
    "**Step 1: Tokenization**\n",
    "- Sentence 1: [\"I\", \"love\", \"data\", \"science\"]\n",
    "- Sentence 2: [\"Data\", \"science\", \"is\", \"amazing\"]\n",
    "- Sentence 3: [\"Machine\", \"learning\", \"and\", \"data\", \"science\", \"are\", \"important\"]\n",
    "\n",
    "**Step 2: Vocabulary Creation**\n",
    "- Vocabulary: ['I', 'love', 'data', 'science', 'is', 'amazing', 'machine', 'learning', 'and', 'are', 'important']\n",
    "\n",
    "**Step 3: Frequency Count (Document-Term Matrix)**\n",
    "|         | I | love | data | science | is | amazing | machine | learning | and | are | important |\n",
    "|---------|---|------|------|---------|----|---------|---------|----------|-----|-----|-----------|\n",
    "| **Doc 1** | 1 | 1    | 1    | 1       | 0  | 0       | 0       | 0        | 0   | 0   | 0         |\n",
    "| **Doc 2** | 0 | 0    | 1    | 1       | 1  | 1       | 0       | 0        | 0   | 0   | 0         |\n",
    "| **Doc 3** | 0 | 0    | 1    | 1       | 0  | 0       | 1       | 1        | 1   | 1   | 1         |\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Case of Counter-Vectorization**\n",
    "Counter-vectorization is particularly useful for tasks like:\n",
    "- **Text Classification** (spam detection, sentiment analysis)\n",
    "- **Topic Modeling**\n",
    "- **Clustering** (grouping similar documents)\n",
    "  \n",
    "It is a simple, yet effective, way to convert text into a form that machine learning models can understand.\n",
    "\n",
    "Would you like to dive deeper into a specific application of counter-vectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f927e-937a-4180-bbea-f8e0c8847b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
