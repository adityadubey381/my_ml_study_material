{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a3dcf9f-cf82-413f-9c14-0aaf9ce17ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, RFE, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e79aefbf-49e1-4192-bf5a-3fe8b1b44631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f948cc3e-68cd-4c62-98ea-9fbda18f6134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9586038b-4dd6-4435-b43e-c791d79f6f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7d9fb-a5c5-447a-8bb3-d19087ba835f",
   "metadata": {},
   "source": [
    "# 1. Filter Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790aabaf-c82a-4132-af97-b03f07ec09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filter Method (Chi-Square) - Selected Features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chi-Square Test (for categorical features, we discretize data)\n",
    "X_chi2 = X.apply(lambda x: pd.cut(x, bins=3, labels=False))  # Convert to categorical\n",
    "chi2_selector = SelectKBest(score_func=chi2, k=2)\n",
    "X_chi2_selected = chi2_selector.fit_transform(X_chi2, y)\n",
    "print(\"\\nFilter Method (Chi-Square) - Selected Features:\", chi2_selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e86b03-e617-4565-bb49-306599d14772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Method (Variance Threshold) - Remaining Features: [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Variance Threshold (removes low variance features)\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "X_var_selected = var_thresh.fit_transform(X)\n",
    "print(\"Filter Method (Variance Threshold) - Remaining Features:\", var_thresh.get_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4000358-e229-4d77-9591-dcaebdff9912",
   "metadata": {},
   "source": [
    "# 2. Wrapper Methods \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaed0a57-107b-466b-9904-864988db8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a9d4b7-2ee2-4aa3-b323-93e2b95e2470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrapper Method (RFE) - Selected Features: [False  True  True  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya kumar Dubey\\anaconda3\\envs\\dubey\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(model, n_features_to_select=3)\n",
    "X_rfe_selected = rfe.fit_transform(X, y)\n",
    "print(\"\\nWrapper Method (RFE) - Selected Features:\", rfe.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16717099-4156-4939-93f3-ce6859e29fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to improve convergence\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea06b1e4-7fee-4b59-8303-fed84c51fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrapper Method (RFE) - Selected Features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "X_rfe_selected = rfe.fit_transform(X_scaled, y)\n",
    "print(\"\\nWrapper Method (RFE) - Selected Features:\", rfe.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7cdcbc-ebe5-4d92-a11d-4609a105bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapper Method (Forward Selection) - Selected Features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Forward Selection\n",
    "forward_selector = SequentialFeatureSelector(model, n_features_to_select=2, direction='forward')\n",
    "forward_selector.fit(X, y)\n",
    "print(\"Wrapper Method (Forward Selection) - Selected Features:\", forward_selector.get_support())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a40d972d-d682-4045-a4aa-70caf187b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapper Method (Backward Elimination) - Selected Features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Backward Elimination\n",
    "backward_selector = SequentialFeatureSelector(model, n_features_to_select=2, direction='backward')\n",
    "backward_selector.fit(X, y)\n",
    "print(\"Wrapper Method (Backward Elimination) - Selected Features:\", backward_selector.get_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551a49f-3cc6-4e73-bdf6-11ba4e9f6358",
   "metadata": {},
   "source": [
    "# 3. Embedded Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a46952ec-295b-453a-ad96-588b74129340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedded Method (Lasso) - Feature Importance: [[ 0.          2.52095427 -2.82990737  0.        ]\n",
      " [ 0.32855835 -1.79382712  0.66572511 -1.57254851]\n",
      " [-2.62318511 -2.50802931  3.26201459  4.61779287]]\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression (L1 Regularization)\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso.fit(X, y)\n",
    "print(\"\\nEmbedded Method (Lasso) - Feature Importance:\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02d0b44c-0cc4-47a8-891e-f955e9396b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Method (Random Forest) - Feature Importance: [0.11675487 0.0171872  0.39681974 0.4692382 ]\n",
      "sqrt\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Feature Importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "print(\"Embedded Method (Random Forest) - Feature Importance:\", rf.feature_importances_)\n",
    "print(rf.max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdcd404a-2e43-43cb-b4d3-ddea2ed80018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm): 0.11675487043845086\n",
      "sepal width (cm): 0.017187197285106037\n",
      "petal length (cm): 0.39681973620720656\n",
      "petal width (cm): 0.4692381960692365\n"
     ]
    }
   ],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "feature_names = rf.feature_names_in_\n",
    "\n",
    "# Print feature importance with names\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    print(f\"{name}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdc936b7-390b-4004-972c-bb38b5d7dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal width (cm): 0.4692381960692365\n",
      "petal length (cm): 0.39681973620720656\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(rf.feature_importances_)[::-1]  # Sort in descending order\n",
    "for i in sorted_indices[:2]:  # Get top 2 features\n",
    "    print(f\"{rf.feature_names_in_[i]}: {rf.feature_importances_[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8773d-70cf-492f-afe7-22462d512249",
   "metadata": {},
   "source": [
    "# 1. Filter Methods (Preprocessing Step)\n",
    "Selects features before training the model based on statistical tests.\n",
    "\n",
    "Works independently of any machine learning model.\n",
    "\n",
    " **Examples:**\n",
    " \n",
    "Correlation: Remove features highly correlated with others.\n",
    "\n",
    "Variance Threshold: Remove features with very low variance.\n",
    "\n",
    "Chi-Square Test (\n",
    "ùúí\n",
    "2\n",
    "œá \n",
    "2\n",
    " ): Measures dependency between categorical features and target.\n",
    "\n",
    "Mutual Information: Measures how much information one variable provides about another.\n",
    "\n",
    "Best for: High-dimensional datasets, quick preprocessing.\n",
    "\n",
    "# 2. Wrapper Methods (Model-Based)\n",
    "Selects features by training a model and evaluating performance.\n",
    "\n",
    "Computationally expensive but gives better results.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "Forward Selection: Start with no features, add them one by one based on performance.\n",
    "\n",
    "Backward Elimination: Start with all features, remove the least important one by one.\n",
    "\n",
    "Recursive Feature Elimination (RFE): Trains a model and removes the least important features iteratively.\n",
    "\n",
    "Best for: Small to medium datasets where accuracy is more important than speed.\n",
    "\n",
    "# 3. Embedded Methods (Built-in Model Feature Selection)\n",
    "Feature selection is done while training the model.\n",
    "\n",
    "More efficient than Wrapper Methods.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "Lasso Regression (L1 Regularization): Shrinks some feature weights to zero, effectively removing them.\n",
    "\n",
    "Decision Tree-based Models (e.g., Random Forest, XGBoost): Automatically determine feature importance.\n",
    "\n",
    "Best for: Large datasets where computational cost matters.\n",
    "\n",
    "Which One to Use?\n",
    "Feature Selection Method\tWhen to Use?\n",
    "Filter Methods\tLarge datasets, fast selection, before training.\n",
    "Wrapper Methods\tWhen accuracy is more important, for small datasets.\n",
    "Embedded Methods\tWhen using tree-based models or Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c078c8-8f38-4644-aebb-8c0f28959b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
